{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdriaSoria/DL_FinalProject/blob/main/DL_FinalProject_(Second_Approach).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q6vLeXmw2q4"
      },
      "source": [
        "# <font color=CC0000> **Deep Learning**\n",
        "## <font color=CC0000> **Final Project: Energy Consumption Prediction**\n",
        "\n",
        "**P103 - Team L**\n",
        "\n",
        "*   Adrià Soria - 251729\n",
        "*   Judit Viladecans - 251437\n",
        "*   Paula Ceprián - 252503"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9RpHHwbwHtO"
      },
      "source": [
        "# 0. Introduction\n",
        "\n",
        "This implementation presents a deep learning solution for predicting household electricity consumption patterns using Long Short-Term Memory (LSTM) networks. The primary objective is to forecast future power consumption values based on historical usage data, helping to anticipate energy demands at the household level. By analyzing temporal sequences of power-related features including global active power, reactive power, voltage, and current intensity, the model learns to recognize and predict consumption patterns across different time periods. This predictive capability has practical applications in smart home energy management, helping households optimize their energy usage and potentially reduce costs.\n",
        "\n",
        "The focus here is to:\n",
        "\n",
        "- **Train and run** a predictive model using  a sequence-to-sequence architecture with LSTM neural networks to forecast household electricity consumption.\n",
        "- **Iteratively enhance the basic LSTM architecture** through various optimization strategies to maximize prediction accuracy.\n",
        "- **Exploration of advanced features in the model design**, such as stateful LSTM layers and time series cross-validation, to improve upon the basic implementation and achieve more robust predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Model Design"
      ],
      "metadata": {
        "id": "yVCdvUFuLDbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Import Basic Libraries and Dataset\n",
        "In this section, we import the essential libraries for the model architecture design. The `clean_dataset.csv` dataset is loaded to preprocess and start the model training."
      ],
      "metadata": {
        "id": "wC3l7FAMLMh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMAvdNO4C8Kr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "from math import sqrt\n",
        "from collections import deque\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, Bidirectional, Input\n",
        "from tensorflow.keras.layers import Flatten, TimeDistributed\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ppnj9oOm88D",
        "outputId": "dca7cd7b-1e7f-42be-e9ab-31f50e6c2ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/Shareddrives/Deep Learning 2025/UPF_Deep_Learning_2025/Project/' #Change path to your dataset location\n",
        "\n",
        "os.chdir(project_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P8XgcMcFQUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7d7507-a1d9-4ef7-ed63-578faa23cea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial data types:\n",
            "Datetime                  object\n",
            "Date                      object\n",
            "Time                      object\n",
            "Global Active Power      float64\n",
            "Global Reactive Power    float64\n",
            "Voltage                  float64\n",
            "Global Intensity         float64\n",
            "Sub Metering 1           float64\n",
            "Sub Metering 2           float64\n",
            "Sub Metering 3           float64\n",
            "Hour                       int64\n",
            "Year                       int64\n",
            "Year-Month                object\n",
            "Month                      int64\n",
            "Month-Day                 object\n",
            "dtype: object\n",
            "\n",
            "Final data types:\n",
            "Global_Active_Power      float64\n",
            "Global_Reactive_Power    float64\n",
            "Voltage                  float64\n",
            "Global_Intensity         float64\n",
            "Hour                       int32\n",
            "Month                      int32\n",
            "Day                        int32\n",
            "dtype: object\n",
            "\n",
            "Final columns:\n",
            "['Global_Active_Power', 'Global_Reactive_Power', 'Voltage', 'Global_Intensity', 'Hour', 'Month', 'Day']\n",
            "\n",
            "Shape of dataset: (34168, 7)\n",
            "\n",
            "First few rows of processed data:\n",
            "                     Global_Active_Power  Global_Reactive_Power     Voltage  \\\n",
            "Datetime                                                                      \n",
            "2006-12-16 17:00:00             4.222889               0.229000  234.643889   \n",
            "2006-12-16 18:00:00             3.632200               0.080033  234.580167   \n",
            "2006-12-16 19:00:00             3.400233               0.085233  233.232500   \n",
            "2006-12-16 20:00:00             3.268567               0.075100  234.071500   \n",
            "2006-12-16 21:00:00             3.056467               0.076667  237.158667   \n",
            "\n",
            "                     Global_Intensity  Hour  Month  Day  \n",
            "Datetime                                                 \n",
            "2006-12-16 17:00:00         18.100000    17     12   16  \n",
            "2006-12-16 18:00:00         15.600000    18     12   16  \n",
            "2006-12-16 19:00:00         14.503333    19     12   16  \n",
            "2006-12-16 20:00:00         13.916667    20     12   16  \n",
            "2006-12-16 21:00:00         13.046667    21     12   16  \n",
            "\n",
            "Dataset after preprocessing:\n",
            "                     Global_Active_Power  Global_Reactive_Power     Voltage  \\\n",
            "Datetime                                                                      \n",
            "2006-12-16 17:00:00             4.222889               0.229000  234.643889   \n",
            "2006-12-16 18:00:00             3.632200               0.080033  234.580167   \n",
            "2006-12-16 19:00:00             3.400233               0.085233  233.232500   \n",
            "2006-12-16 20:00:00             3.268567               0.075100  234.071500   \n",
            "2006-12-16 21:00:00             3.056467               0.076667  237.158667   \n",
            "\n",
            "                     Global_Intensity  Hour  Month  Day  \n",
            "Datetime                                                 \n",
            "2006-12-16 17:00:00         18.100000    17     12   16  \n",
            "2006-12-16 18:00:00         15.600000    18     12   16  \n",
            "2006-12-16 19:00:00         14.503333    19     12   16  \n",
            "2006-12-16 20:00:00         13.916667    20     12   16  \n",
            "2006-12-16 21:00:00         13.046667    21     12   16  \n",
            "\n",
            "Columns after preprocessing:\n",
            "['Global_Active_Power', 'Global_Reactive_Power', 'Voltage', 'Global_Intensity', 'Hour', 'Month', 'Day']\n",
            "\n",
            "Shape of dataset: (34168, 7)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('clean_dataset.csv', sep=',', low_memory=False, encoding='utf-8')\n",
        "\n",
        "# Print initial data types\n",
        "print(\"Initial data types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# 1. Handle datetime-related columns\n",
        "df['Datetime'] = pd.to_datetime(df['Datetime'])  # Convert to datetime\n",
        "df.set_index('Datetime', inplace=True)  # Set as index\n",
        "\n",
        "# 2. Drop redundant time-related columns since we have datetime index\n",
        "time_columns = ['Date', 'Time', 'Hour', 'Year', 'Year-Month', 'Month', 'Month-Day']\n",
        "df = df.drop(time_columns, axis=1)\n",
        "\n",
        "# 3. Drop sub-metering columns\n",
        "sub_metering_columns = ['Sub Metering 1', 'Sub Metering 2', 'Sub Metering 3']\n",
        "df = df.drop(sub_metering_columns, axis=1)\n",
        "\n",
        "# 4. Clean column names (remove spaces)\n",
        "df.columns = df.columns.str.replace(' ', '_')\n",
        "\n",
        "# 5. Ensure numeric columns are float\n",
        "numeric_columns = ['Global_Active_Power', 'Global_Reactive_Power', 'Voltage', 'Global_Intensity']\n",
        "for col in numeric_columns:\n",
        "    df[col] = df[col].astype('float64')\n",
        "\n",
        "# 6. Sort by datetime index and handle missing values\n",
        "df.sort_index(inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# 7. Resample to hourly data\n",
        "df = df.resample('1h').mean()\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Now extract datetime-based features from the index\n",
        "df['Hour'] = df.index.hour\n",
        "df['Month'] = df.index.month\n",
        "df['Day'] = df.index.day\n",
        "\n",
        "# Print final information about the dataset\n",
        "print(\"\\nFinal data types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nFinal columns:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nShape of dataset:\", df.shape)\n",
        "print(\"\\nFirst few rows of processed data:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset after preprocessing:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns after preprocessing:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nShape of dataset:\", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset captures hourly household power consumption through four electrical parameters (Global Active Power, Global Reactive Power, Voltage, and Global Intensity) across 34,168 measurements starting from December 2006. The data is structured as a time series with measurements taken every hour, starting from December 16, 2006, at 17:00. These four parameters provide a comprehensive view of the household's electrical consumption patterns, which will be used by our LSTM model to learn and predict future consumption values."
      ],
      "metadata": {
        "id": "1ripY1xNKJiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Data Preprocessing\n",
        "\n",
        "#### Moving Average filtering... smoothing our data\n",
        "\n",
        "######## Smothing our data at first\n",
        "df = df.ewm(alpha=0.1).mean()\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# #Dropping the outlier rows with standard deviation\n",
        "factor = 5\n",
        "upper_lim = df['Global_Active_Power'].mean () + df['Global_Active_Power'].std () * factor\n",
        "lower_lim = df['Global_Active_Power'].mean () - df['Global_Active_Power'].std () * factor\n",
        "df = df[(df['Global_Active_Power'] < upper_lim) & (df['Global_Active_Power'] > lower_lim)]\n",
        "\n",
        "####### fill values summer of 2008\n",
        "\n",
        "times = pd.to_datetime(df.index)\n",
        "times = times.strftime(\"%Y-%m-%d\").tolist()\n",
        "temp = []\n",
        "for index,value in enumerate(times):\n",
        "  if(value > '2007-08-08' and value <'2007-09-01'):\n",
        "\n",
        "    #temp.append(float(df['Global_active_power'][index]))\n",
        "    temp.append(float(df.loc[df.index[index], 'Global_Active_Power']))\n",
        "\n",
        "temp = pd.Series(temp)\n",
        "temp = temp.ewm(alpha=0.15).mean()\n",
        "temp = temp.values\n",
        "\n",
        "k=0\n",
        "for index,value in enumerate(times):\n",
        "  if(value > '2008-08-08' and value <'2008-09-01'):\n",
        "    #df['Global_active_power'].iloc[index] = temp[k]\n",
        "    df.loc[df.index[index], 'Global_Active_Power'] = temp[k]\n",
        "    k += 1\n",
        "\n",
        "print(f'df_shape arxika: {df.shape}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_0FcjHyKgoD",
        "outputId": "028f9b9e-6ae7-4a99-f33b-31cc78da70aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_shape arxika: (34153, 7)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We processes this time series data through several crucial steps: it first organizes the readings chronologically and standardizes the data format, then applies an exponential moving average (alpha=0.2) to smooth out short-term fluctuations in the measurements. To ensure data quality, it removes statistical outliers using a three-standard-deviation threshold and handles a specific data anomaly in the summer period of 2008 by filling it with smoothed values from the corresponding period in 2007."
      ],
      "metadata": {
        "id": "W9jpIe_RKrXl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z36FrtJbDihu"
      },
      "source": [
        "### 1.2 LSTM Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section presents the core functions and neural network architecture used for forecasting household power consumption. The code defines key parameters for sequence length, prediction horizon, and model training, and implements utility functions for error calculation, data preprocessing, and time series splitting. At its core, the section introduces a deep learning model based on a stateful LSTM (Long Short-Term Memory) architecture, designed to capture temporal dependencies in sequential power usage data. The model is structured to process sequences of historical measurements and predict future consumption, forming the foundation for the project's predictive analytics."
      ],
      "metadata": {
        "id": "PtovK5YlMFiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2pHs-qZC0FP"
      },
      "outputs": [],
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "#     y_true, y_pred = check_arrays(y_true, y_pred)\n",
        "\n",
        "    ## Note: does not handle mix 1d representation\n",
        "    #if _is_1d(y_true):\n",
        "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
        "\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "\n",
        "def regression_accuracy(y_true, y_pred, tolerance):\n",
        "    \"\"\"\n",
        "    Calcula la \"accuracy\" de un modelo de regresión como el % de predicciones\n",
        "    que caen dentro de un margen relativo de tolerancia\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    within_tolerance = np.abs(y_true - y_pred) <= (tolerance * np.abs(y_true))\n",
        "    return np.mean(within_tolerance) * 100  # en porcentaje\n",
        "\n",
        "\n",
        "def theil_u(yhat, y):\n",
        "\n",
        "  len_yhat = len(yhat)\n",
        "  sum1 = 0\n",
        "  sum2 = 0\n",
        "\n",
        "  for i in range(len_yhat-1):\n",
        "\n",
        "    sum1 += ( (yhat[i+1] - y[i+1]) / y[i] )**2\n",
        "    sum2 += ( (y[i+1] - y[i]) / y[i] )**2\n",
        "\n",
        "  return sqrt(sum1/sum2)\n",
        "\n",
        "\n",
        "def plot_history(loss, val_loss, epochs):\n",
        "\n",
        "  plt.figure(figsize=[15,8])\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(range(epochs), loss, label='Train Error')\n",
        "  plt.plot(range(epochs), val_loss, label = 'Val Error')\n",
        "  plt.ylim([0.00,0.15])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def preprocess_df(df, shuffle=False):\n",
        "\n",
        "    sequential_data = []                    # this is a list that will CONTAIN the sequences\n",
        "    prev_days = deque(maxlen = SEQ_LEN)     # These will be our actual sequences.\n",
        "                                            # They are made with deque, which keeps the maximum length\n",
        "                                            # by popping out older values as new ones come in\n",
        "    for i in df.values:                                             # iterate over the values\n",
        "        prev_days.append([n for n in i[:-1]])                       # store all but the label\n",
        "        if len(prev_days) == SEQ_LEN:                               # make sure we have 30 sequences!\n",
        "            sequential_data.append([np.array(prev_days), i[-1]])    # append those bad boys!\n",
        "\n",
        "\n",
        "    if(shuffle == True):\n",
        "      random.shuffle(sequential_data)                                 # shuffle for good measure.\n",
        "\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for seq, target in sequential_data:  # going over our new sequential data\n",
        "        X.append(seq)                    # X is the sequences (features)\n",
        "        y.append(target)                 # y is the targets/labels\n",
        "\n",
        "    return np.array(X), np.array(y)  # return X and y...and make X a numpy array!\n",
        "\n",
        "\n",
        "def train_length(length, batch_size):\n",
        "\n",
        "  length_values = []\n",
        "  for x in range( int(length)-100, int(length) ):\n",
        "    modulo = x % batch_size\n",
        "    if(modulo == 0 ):\n",
        "      length_values.append(x)\n",
        "\n",
        "  return ( max(length_values) )\n",
        "\n",
        "\n",
        "def split_data(df, percent):\n",
        "\n",
        "  length = len(df)\n",
        "  test_index = int(length*percent)\n",
        "  train_index = length - test_index\n",
        "  test_df = df[train_index:]\n",
        "  df = df[:train_index]\n",
        "\n",
        "  return test_df, df\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    model = Sequential([\n",
        "        Input(shape=(train_x.shape[1], train_x.shape[2]), batch_size=BATCH_SIZE),\n",
        "\n",
        "        # LSTM layer\n",
        "        LSTM(36, stateful=True, return_sequences=False),\n",
        "\n",
        "        # Fully Connected layer\n",
        "        Dense(64, activation='relu'),\n",
        "\n",
        "        # Dropout for regularization\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Output layer (regression)\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss='mae',\n",
        "        optimizer='adam',\n",
        "        metrics=['mse', 'mae']\n",
        "    )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model Training"
      ],
      "metadata": {
        "id": "iPO_c0UNM340"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section details the training procedure for the LSTM-based power consumption forecasting model. The code transforms the time series data into a supervised learning format, where the model learns to predict future power usage based on sequences of past measurements. It employs time series cross-validation to robustly assess model performance, splitting the data into training, validation, and test sets in a way that respects the temporal order of the data. During each split, the model is trained, validated, and evaluated using several performance metrics, with careful handling of data scaling and LSTM state management. This systematic approach ensures that the model is both well-trained and fairly evaluated on unseen data, providing reliable insights into its predictive capabilities."
      ],
      "metadata": {
        "id": "IFADfY4zM73G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 100                    # how long of a preceeding sequence to collect for RNN (in 1hour minutes)\n",
        "FUTURE_PERIOD_PREDICT = 1       # how far into the future are we trying to predict? (in hours)\n",
        "EPOCHS = 30                     # how many passes through our data\n",
        "BATCH_SIZE = 64                 # how many batches? Try smaller batch if you're getting OOM (out of memory) errors."
      ],
      "metadata": {
        "id": "BTjMA-GWMlNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9RYXomjV-NvA",
        "outputId": "9410fcbe-d838-4222-a03e-2500a50117b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Global_Active_Power    future\n",
            "Datetime                                          \n",
            "2006-12-16 22:00:00             3.191471  2.974897\n",
            "2006-12-16 23:00:00             2.974897  2.783085\n",
            "2006-12-17 00:00:00             2.783085  2.875533\n",
            "2006-12-17 01:00:00             2.875533  2.677740\n",
            "2006-12-17 02:00:00             2.677740  2.529743\n",
            "2006-12-17 03:00:00             2.529743  2.485988\n",
            "2006-12-17 04:00:00             2.485988  2.420388\n",
            "2006-12-17 05:00:00             2.420388  2.275543\n",
            "2006-12-17 06:00:00             2.275543  2.192996\n",
            "2006-12-17 07:00:00             2.192996  2.155875\n",
            "Yooooooo:(34133, 8)\n",
            "df:(25600, 8)  test_df:(8533, 8)\n",
            "df_shape(23040, 8)\n",
            "test_shape(8533, 8)\n",
            "Valid_shape(2560, 8)\n",
            "train_len before:22941 test_len:8434\n",
            "train_len after modulo:22912 test_len:8384\n",
            "Train_x shape:(22912, 100, 7) Train_y shape:(22912,)\n",
            "valid_x shape:(2432, 100, 7) valid_y shape:(2432,)\n",
            "Test_x shape:(8384, 100, 7) Test_y shape:(8384,) \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m36\u001b[0m)               │         \u001b[38;5;34m6,336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │         \u001b[38;5;34m2,368\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,769\u001b[0m (34.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,769</span> (34.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,769\u001b[0m (34.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,769</span> (34.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split: 2 Epochs: 0/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0848 - mae: 0.0848 - mse: 0.0160 - val_loss: 0.0393 - val_mae: 0.0393 - val_mse: 0.0025\n",
            "Split: 2 Epochs: 1/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0375 - mae: 0.0375 - mse: 0.0025 - val_loss: 0.0207 - val_mae: 0.0207 - val_mse: 8.2058e-04\n",
            "Split: 2 Epochs: 2/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0299 - mae: 0.0299 - mse: 0.0017 - val_loss: 0.0187 - val_mae: 0.0187 - val_mse: 5.1313e-04\n",
            "Split: 2 Epochs: 3/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0013 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 4.0415e-04\n",
            "Split: 2 Epochs: 4/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0011 - val_loss: 0.0149 - val_mae: 0.0149 - val_mse: 4.6744e-04\n",
            "Split: 2 Epochs: 5/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0226 - mae: 0.0226 - mse: 9.7708e-04 - val_loss: 0.0151 - val_mae: 0.0151 - val_mse: 3.7722e-04\n",
            "Split: 2 Epochs: 6/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0218 - mae: 0.0218 - mse: 9.2156e-04 - val_loss: 0.0142 - val_mae: 0.0142 - val_mse: 3.5460e-04\n",
            "Split: 2 Epochs: 7/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0217 - mae: 0.0217 - mse: 9.3435e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 4.0945e-04\n",
            "Split: 2 Epochs: 8/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.0211 - mse: 8.7671e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.9156e-04\n",
            "Split: 2 Epochs: 9/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0212 - mae: 0.0212 - mse: 9.0679e-04 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 4.0698e-04\n",
            "Split: 2 Epochs: 10/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.0211 - mse: 8.5470e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.3582e-04\n",
            "Split: 2 Epochs: 11/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0212 - mae: 0.0212 - mse: 8.5727e-04 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 3.7724e-04\n",
            "Split: 2 Epochs: 12/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0203 - mae: 0.0203 - mse: 7.9495e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.4227e-04\n",
            "Split: 2 Epochs: 13/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0209 - mae: 0.0209 - mse: 8.5716e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 3.4436e-04\n",
            "Split: 2 Epochs: 14/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0206 - mae: 0.0206 - mse: 8.4104e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 4.2086e-04\n",
            "Split: 2 Epochs: 15/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0204 - mae: 0.0204 - mse: 8.1733e-04 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 4.6776e-04\n",
            "Split: 2 Epochs: 16/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0209 - mae: 0.0209 - mse: 8.5143e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 4.1445e-04\n",
            "Split: 2 Epochs: 17/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0204 - mae: 0.0204 - mse: 8.2182e-04 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 4.3183e-04\n",
            "Split: 2 Epochs: 18/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0207 - mae: 0.0207 - mse: 8.2755e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.7022e-04\n",
            "Split: 2 Epochs: 19/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0202 - mae: 0.0202 - mse: 7.9789e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.3489e-04\n",
            "Split: 2 Epochs: 20/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0202 - mae: 0.0202 - mse: 8.2805e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.4616e-04\n",
            "Split: 2 Epochs: 21/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0204 - mae: 0.0204 - mse: 8.1565e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3418e-04\n",
            "Split: 2 Epochs: 22/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0201 - mae: 0.0201 - mse: 8.1353e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.5987e-04\n",
            "Split: 2 Epochs: 23/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0198 - mae: 0.0198 - mse: 7.6107e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.2784e-04\n",
            "Split: 2 Epochs: 24/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0202 - mae: 0.0202 - mse: 8.1607e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.7519e-04\n",
            "Split: 2 Epochs: 25/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0198 - mae: 0.0198 - mse: 7.6999e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.2676e-04\n",
            "Split: 2 Epochs: 26/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0199 - mae: 0.0199 - mse: 7.8698e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.8223e-04\n",
            "Split: 2 Epochs: 27/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0202 - mae: 0.0202 - mse: 8.1026e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.6708e-04\n",
            "Split: 2 Epochs: 28/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0195 - mae: 0.0195 - mse: 7.5335e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4563e-04\n",
            "Split: 2 Epochs: 29/30\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0199 - mae: 0.0199 - mse: 7.8450e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.2653e-04\n",
            "Test loss: 0.012827906757593155\n",
            "Test MSE: 0.00030901769059710205\n",
            "Test MAE: 0.012827906757593155\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Test RMSE: 0.05468122264482539\n",
            "Test R^2 score: 0.9788855257559181\n",
            "Test MAPE: 3.9148%\n",
            "Test Accuracy (±10% tolerance): 93.4757%\n"
          ]
        }
      ],
      "source": [
        "### Create supervised learning\n",
        "\n",
        "\n",
        "df['future'] = df[\"Global_Active_Power\"].shift(-FUTURE_PERIOD_PREDICT)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df[['Global_Active_Power','future']].head(10))\n",
        "\n",
        "\n",
        "##### cross validation for time series..... ##################################################################################################################\n",
        "\n",
        "count = 0\n",
        "\n",
        "#### Evaluation metrics.....\n",
        "evaluate_loss = []\n",
        "evaluate_mse = []\n",
        "evaluate_mlog = []\n",
        "evaluate_rmse = []\n",
        "evaluate_r2 = []\n",
        "evaluate_mape = []\n",
        "evaluate_accuracy = []\n",
        "\n",
        "val_loss = []\n",
        "loss = []\n",
        "\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "for train_index, test_index in tscv.split(df):\n",
        "\n",
        "  if (count >= 2 ):\n",
        "\n",
        "    df2 = df.copy()\n",
        "\n",
        "    print(f'df:{df2[:len(train_index)].shape}  test_df:{df2[len(train_index):len(train_index)+len(test_index)].shape}')\n",
        "\n",
        "    test_df = df2[len(train_index):len(train_index)+len(test_index)]\n",
        "    df2 = df2[:len(train_index)]\n",
        "    valid_df, df2 = split_data(df2, 0.1)\n",
        "\n",
        "    print(f'df_shape{df2.shape}')\n",
        "    print(f'test_shape{test_df.shape}')\n",
        "    print(f'Valid_shape{valid_df.shape}')\n",
        "\n",
        "    df2.dropna(inplace=True)\n",
        "    valid_df.dropna(inplace=True)\n",
        "    test_df.dropna(inplace=True)\n",
        "\n",
        "  #### scale our data\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "    cols = [col for col in df.columns if col not in ['time']]\n",
        "\n",
        "    df2[cols] = scaler.fit_transform(df2[cols])\n",
        "    df2.dropna(inplace=True)\n",
        "\n",
        "    test_df[cols] = scaler.transform(test_df[cols])\n",
        "    test_df.dropna(inplace=True)\n",
        "\n",
        "    valid_df[cols] = scaler.transform(valid_df[cols])\n",
        "    valid_df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "    train_x, train_y = preprocess_df(df2, shuffle=True)\n",
        "    valid_x, valid_y = preprocess_df(valid_df, shuffle=False)\n",
        "    test_x, test_y = preprocess_df(test_df, shuffle=False)\n",
        "\n",
        "    train_len = train_x.shape[0]\n",
        "    valid_len = valid_x.shape[0]\n",
        "    test_len = test_x.shape[0]\n",
        "    print(f'train_len before:{train_len} test_len:{test_len}')\n",
        "\n",
        "    train_len = train_length(train_len, BATCH_SIZE)\n",
        "    valid_len = train_length(valid_len, BATCH_SIZE)\n",
        "    test_len = train_length(test_len, BATCH_SIZE)\n",
        "\n",
        "    print(f'train_len after modulo:{train_len} test_len:{test_len}')\n",
        "\n",
        "    train_x = train_x[:train_len]\n",
        "    train_y = train_y[:train_len]\n",
        "\n",
        "    valid_x = valid_x[:valid_len]\n",
        "    valid_y = valid_y[:valid_len]\n",
        "\n",
        "    test_x = test_x[:test_len]\n",
        "    test_y = test_y[:test_len]\n",
        "\n",
        "    print(f'Train_x shape:{train_x.shape} Train_y shape:{train_y.shape}')\n",
        "    print(f'valid_x shape:{valid_x.shape} valid_y shape:{valid_y.shape}')\n",
        "    print(f'Test_x shape:{test_x.shape} Test_y shape:{test_y.shape} \\n')\n",
        "\n",
        "\n",
        "    \"\"\".....The model.....\"\"\"\n",
        "\n",
        "    model = get_model()\n",
        "    model.summary()\n",
        "\n",
        "    \"\"\".....train model.....\"\"\"\n",
        "\n",
        "    # Stateful LSTM\n",
        "\n",
        "    for i in range(EPOCHS):\n",
        "      print(f'Split: {count} Epochs: {i}/{EPOCHS}')\n",
        "\n",
        "      history = model.fit(\n",
        "        train_x, train_y,\n",
        "        batch_size = BATCH_SIZE,\n",
        "        epochs = 1,\n",
        "        validation_data = (valid_x, valid_y),\n",
        "      )\n",
        "\n",
        "\n",
        "      val_loss.append(history.history['val_loss'])\n",
        "      loss.append(history.history['loss'])\n",
        "\n",
        "      # Reset states for all LSTM layers\n",
        "      for layer in model.layers:\n",
        "          if isinstance(layer, LSTM):\n",
        "              layer.reset_states()\n",
        "\n",
        "\n",
        "    \"\"\" Evaluate model.......  \"\"\"\n",
        "\n",
        "    # Reset states before evaluation\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, LSTM):\n",
        "            layer.reset_states()\n",
        "\n",
        "    score = model.evaluate(test_x, test_y,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test MSE:', score[1])\n",
        "    print('Test MAE:', score[2])\n",
        "\n",
        "    evaluate_loss.append(score[0])\n",
        "    evaluate_mse.append(score[1])\n",
        "\n",
        "    ######## plot loss & val_loss\n",
        "\n",
        "    plot_history(loss, val_loss, EPOCHS)\n",
        "\n",
        "\n",
        "    #### make & evaluate our prediction\n",
        "\n",
        "    # Reset states before prediction\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, LSTM):\n",
        "            layer.reset_states()\n",
        "\n",
        "    yhat = model.predict(test_x, batch_size=BATCH_SIZE)\n",
        "\n",
        "    ###### invert scaling for forecast\n",
        "    # Create a dummy array with same shape as original data\n",
        "    predict = np.zeros(shape=(len(yhat), len(df.columns)))\n",
        "    # Put our predictions in the Global_active_power column position\n",
        "    predict[:, df.columns.get_loc('Global_Active_Power')] = yhat[:, 0]\n",
        "\n",
        "    inv_yhat = scaler.inverse_transform(predict)\n",
        "    # Get back just the Global_active_power predictions\n",
        "    inv_yhat = inv_yhat[:, df.columns.get_loc('Global_Active_Power')]\n",
        "\n",
        "    ###### invert scaling for actual\n",
        "    actual = np.zeros(shape=(len(test_y), len(df.columns)))\n",
        "    actual[:, df.columns.get_loc('Global_Active_Power')] = test_y\n",
        "\n",
        "    inv_y = scaler.inverse_transform(actual)\n",
        "    inv_y = inv_y[:, df.columns.get_loc('Global_Active_Power')]\n",
        "\n",
        "    ##### calculate RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "    print(f'Test RMSE: {rmse}')\n",
        "    evaluate_rmse.append(rmse)\n",
        "\n",
        "    ##### calculate R^2 metric\n",
        "    r2 = r2_score(inv_y, inv_yhat)\n",
        "    print(f'Test R^2 score: {r2}')\n",
        "    evaluate_r2.append(r2)\n",
        "\n",
        "    ##### calculate MAPE\n",
        "    mape = np.mean(np.abs((inv_y - inv_yhat) / inv_y)) * 100\n",
        "    print(f'Test MAPE: {mape:.4f}%')\n",
        "    evaluate_mape.append(mape)\n",
        "\n",
        "    ##### calculate regression-based accuracy\n",
        "    accuracy = regression_accuracy(inv_y, inv_yhat, tolerance=0.1)\n",
        "    print(f'Test Accuracy (±10% tolerance): {accuracy:.4f}%')\n",
        "    evaluate_accuracy.append(accuracy)\n",
        "\n",
        "  count += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Evaluation"
      ],
      "metadata": {
        "id": "4Ij9AcdwNP2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section presents the aggregated results of the model’s predictive performance. By averaging key metrics across all validation splits, it provides a concise summary of how accurately the LSTM model forecasts household power consumption on unseen data."
      ],
      "metadata": {
        "id": "w5DKvf2eNklR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za-EhFXImtSz",
        "outputId": "aa19ccfe-ece6-4374-81c5-eb32789a0d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Avg Loss:0.06662722676992416\n",
            "Avg MSE:0.008261439390480518\n",
            "Avg RMSE:0.23285796549604376\n",
            "Avg R2:0.7453055639400753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "avg_loss = np.average(evaluate_loss)\n",
        "avg_mse = np.average(evaluate_mse)\n",
        "avg_rmse = np.average(evaluate_rmse)\n",
        "avg_r2 = np.average(evaluate_r2)\n",
        "#avg_theil = np.average(evaluate_theil)\n",
        "avg_mape = np.average(evaluate_mape)\n",
        "\n",
        "print('\\n')\n",
        "print(f'Avg Loss:{avg_loss}')\n",
        "print(f'Avg MSE:{avg_mse}')\n",
        "print(f'Avg RMSE:{avg_rmse}')\n",
        "print(f'Avg R2:{avg_r2}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}